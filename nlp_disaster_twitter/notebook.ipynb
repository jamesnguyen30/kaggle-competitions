{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Competition: https://www.kaggle.com/c/nlp-getting-started/data?select=train.cs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import argparse"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "DATASET_ROOT = './tweets/'\n",
    "TRAIN_PATH = os.path.join(DATASET_ROOT, 'train.csv')\n",
    "TEST_PATH = os.path.join(DATASET_ROOT, 'test.csv')\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    \n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH, index_col='id')\n",
    "\n",
    "train_df.head()\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword location                                               text  target\n",
       "id                                                                            \n",
       "1      NaN      NaN  Our Deeds are the Reason of this #earthquake M...       1\n",
       "4      NaN      NaN             Forest fire near La Ronge Sask. Canada       1\n",
       "5      NaN      NaN  All residents asked to 'shelter in place' are ...       1\n",
       "6      NaN      NaN  13,000 people receive #wildfires evacuation or...       1\n",
       "7      NaN      NaN  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "test_df = pd.read_csv(TEST_PATH, index_col = 'id')\n",
    "\n",
    "test_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword location                                               text\n",
       "id                                                                    \n",
       "0      NaN      NaN                 Just happened a terrible car crash\n",
       "2      NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "3      NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "9      NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data shape and missing values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print('Train shape ', train_df.shape)\n",
    "print('Test shape ', test_df.shape)\n",
    "\n",
    "print(\"\\nTrain dataset missing values\")\n",
    "print(train_df.isnull().sum())\n",
    "print('\\nUnique values in location')\n",
    "\n",
    "train_values = train_df['location'].value_counts(dropna = True, sort = True)\n",
    "print(train_values)\n",
    "\n",
    "print('\\nUnique values in keywords')\n",
    "print(train_df['keyword'].value_counts(dropna = True, sort = True))\n",
    "\n",
    "print(\"\\nTest dataset missing values\")\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "print()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train shape  (7613, 4)\n",
      "Test shape  (3263, 3)\n",
      "\n",
      "Train dataset missing values\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n",
      "\n",
      "Unique values in location\n",
      "USA                         104\n",
      "New York                     71\n",
      "United States                50\n",
      "London                       45\n",
      "Canada                       29\n",
      "                           ... \n",
      "Somewhere out there           1\n",
      "? Jet Life ?                  1\n",
      "Louavul, KY                   1\n",
      "Land Of The Kings             1\n",
      "THE WORLD T.G.G / M.M.M       1\n",
      "Name: location, Length: 3341, dtype: int64\n",
      "\n",
      "Unique values in keywords\n",
      "fatalities               45\n",
      "deluge                   42\n",
      "armageddon               42\n",
      "harm                     41\n",
      "body%20bags              41\n",
      "                         ..\n",
      "forest%20fire            19\n",
      "epicentre                12\n",
      "threat                   11\n",
      "inundation               10\n",
      "radiation%20emergency     9\n",
      "Name: keyword, Length: 221, dtype: int64\n",
      "\n",
      "Test dataset missing values\n",
      "keyword       26\n",
      "location    1105\n",
      "text           0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process the tweets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "def clean_text (text):\n",
    "    text = re.sub(r\"([^a-zA-Z']+)|(https?:\\S+)|(www.\\S+)\",  r\" \", text)\n",
    "    return text\n",
    "\n",
    "r = random.randint(0, train_df.shape[0])\n",
    "\n",
    "sample = train_df['text'].iloc[r]\n",
    "\n",
    "print('Original sample: ', sample)\n",
    "\n",
    "sample = clean_text(sample)\n",
    "\n",
    "print('Sample cleaned: ', sample)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original sample:  WWI WWII JAPANESE ARMY NAVY MILITARY JAPAN LEATHER WATCH WAR MIDO WW1 2 - Full read by eBay http://t.co/obfD7e4QcP http://t.co/yAZjE5OwVk\n",
      "Sample cleaned:  WWI WWII JAPANESE ARMY NAVY MILITARY JAPAN LEATHER WATCH WAR MIDO WW Full read by eBay    \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "train_df['text'].apply(clean_text)\n",
    "\n",
    "test_df['text'].apply(clean_text)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id\n",
       "0                       Just happened a terrible car crash\n",
       "2        Heard about earthquake is different cities sta...\n",
       "3        there is a forest fire at spot pond geese are ...\n",
       "9                    Apocalypse lighting Spokane wildfires\n",
       "11              Typhoon Soudelor kills in China and Taiwan\n",
       "                               ...                        \n",
       "10861    EARTHQUAKE SAFETY LOS ANGELES SAFETY FASTENERS...\n",
       "10865    Storm in RI worse than last hurricane My city ...\n",
       "10868                   Green Line derailment in Chicago  \n",
       "10874           MEG issues Hazardous Weather Outlook HWO  \n",
       "10875     CityofCalgary has activated its Municipal Eme...\n",
       "Name: text, Length: 3263, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Vectorize the text"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "#Process training first, test set will be processed the same way but it comes later\n",
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "\n",
    "train_vectors = count_vectorizer.fit_transform(train_df['text'])\n",
    "\n",
    "print('Train vector shape ', train_vectors.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train vector shape  (7613, 21637)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "r = random.randint(0, train_vectors.shape[0])\n",
    "print('Converted \\n', train_vectors[r])\n",
    "print(type(train_vectors[r]))\n",
    "print('\\n Original training sample \\n', train_df.iloc[r])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converted \n",
      "   (0, 2192)\t1\n",
      "  (0, 1984)\t1\n",
      "  (0, 18659)\t1\n",
      "  (0, 12929)\t1\n",
      "  (0, 11176)\t1\n",
      "  (0, 9304)\t1\n",
      "  (0, 4517)\t1\n",
      "  (0, 12191)\t2\n",
      "  (0, 2358)\t1\n",
      "  (0, 19703)\t1\n",
      "  (0, 20770)\t1\n",
      "  (0, 6195)\t1\n",
      "  (0, 18828)\t1\n",
      "  (0, 20369)\t1\n",
      "  (0, 4273)\t1\n",
      "  (0, 19335)\t1\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "\n",
      " Original training sample \n",
      " keyword                                                 drown\n",
      "location                                        @notoriousD12\n",
      "text        Throw that water at me until I drown and my la...\n",
      "target                                                      0\n",
      "Name: 4159, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building models "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "from sklearn import model_selection, linear_model\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "clf = linear_model.RidgeClassifier()\n",
    "\n",
    "scores = model_selection.cross_val_score(clf, train_vectors, train_df['target'], cv = 10, scoring='f1')\n",
    "\n",
    "print(scores)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.6148532  0.48       0.44267516 0.44748858 0.52058824 0.56426332\n",
      " 0.49911504 0.47670251 0.62611276 0.69101124]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NOTE!! DO NOT TOUCH THE TEST SET BEFORE YOU'RE CONFIDENT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "#Final validation here"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "2.7.16",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 2.7.16 64-bit"
  },
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}